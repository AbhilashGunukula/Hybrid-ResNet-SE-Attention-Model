{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting AI-Generated Images Using a Hybrid ResNet-SE Attention Model\n",
    "\n",
    "\n",
    "### Mounting the Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd2iPyhCeEo8",
    "outputId": "c086e7b0-9d3c-4d09-a942-688b3b28775e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2_7cJo-NeXEB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "from lime import lime_image\n",
    "import shap\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7azF368XeXBM"
   },
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZWLq88CTe9gh"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"D:/IndependentStudy/AIGeneratedImageIdentification/Dataset\"\n",
    "img_height = 224\n",
    "img_width  = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Se8At_8IfCKu",
    "outputId": "6e01ebf8-d1d9-4f76-a32d-4eb875f198e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 2 classes.\n",
      "Using 80000 files for training.\n",
      "Found 100000 files belonging to 2 classes.\n",
      "Using 20000 files for validation.\n",
      "Found 20000 files belonging to 2 classes.\n",
      "Class names: ['FAKE', 'REAL']\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(dataset_path, \"train\"), \n",
    "    validation_split = 0.2, subset = \"training\", seed = 123, image_size = (img_height, img_width), batch_size = batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(dataset_path, \"train\"), \n",
    "    validation_split = 0.2, subset = \"validation\", seed = 123, image_size = (img_height, img_width), batch_size = batch_size)\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(dataset_path, \"test\"), \n",
    "    image_size = (img_height, img_width), batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing & Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MutrnFSLfFAt"
   },
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds   = val_ds.map(lambda x,   y: (normalization_layer(x), y))\n",
    "test_ds  = test_ds.map(lambda x,  y: (normalization_layer(x), y))\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds   = val_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "test_ds  = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "####  Squeeze - and - Excitation (SE) Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x-kNeTPDfHzn"
   },
   "outputs": [],
   "source": [
    "def se_block(input_tensor, reduction_ratio = 16):\n",
    "    channel_axis = -1\n",
    "    filters = input_tensor.shape[channel_axis]\n",
    "\n",
    "    se = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "    se = layers.Dense(filters // reduction_ratio, activation = 'relu')(se)\n",
    "    se = layers.Dense(filters, activation = 'sigmoid')(se)\n",
    "    se = layers.Reshape((1, 1, filters))(se)\n",
    "    return layers.multiply([input_tensor, se])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet-SE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MVNviQtifJYj"
   },
   "outputs": [],
   "source": [
    "def build_resnet_se_model(input_shape = (224, 224, 3)):\n",
    "    base_model = ResNet50(include_top = False, weights = 'imagenet', input_shape = input_shape)\n",
    "    base_model.trainable = True\n",
    "\n",
    "    inputs = layers.Input(shape = input_shape)\n",
    "    x = base_model(inputs, training = True)\n",
    "    x = se_block(x)  \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation = 'relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model integrates a ResNet50 backbone with a Squeeze-and-Excitation (SE) block to enhance feature channel importance using attention.\n",
    "\n",
    "* Useing transfer learning with ImageNet weights and supports fine-tuning for better performance on custom binary classification tasks.\n",
    "\n",
    "* A combination of global average pooling, dense layers, and dropout enables efficient feature reduction and regularization.\n",
    "\n",
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "PSYb4clSfLAC",
    "outputId": "2279fa59-47eb-408a-f673-52683f965c31"
   },
   "outputs": [],
   "source": [
    "model = build_resnet_se_model()\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model has ~24.3 million trainable parameters, primarily from the ResNet50 backbone, enabling strong feature extraction.\n",
    "\n",
    "* An SE block integrated after ResNet50 to apply channel-wise attention, enhancing important features.\n",
    "\n",
    "* The architecture ends with dense layers and dropout, suited for binary classification tasks with added regularization.\n",
    "\n",
    "\n",
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fye9YoDYfMb6",
    "outputId": "a2db4d90-6e5e-4b34-eddf-ef7ce9dea7b7"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data = val_ds, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "id": "96L_WCBdbmym",
    "outputId": "65daa267-0280-4df0-c645-e8b6890bc566"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc     = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    prec     = history.history['precision']\n",
    "    val_prec = history.history['val_precision']\n",
    "    \n",
    "    recall     = history.history['recall']\n",
    "    val_recall = history.history['val_recall']\n",
    "    \n",
    "    loss     = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize = (16, 10))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label = 'Train Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label = 'Val Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs_range, prec, label = 'Train Precision')\n",
    "    plt.plot(epochs_range, val_prec, label = 'Val Precision')\n",
    "    plt.legend()\n",
    "    plt.title('Precision')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs_range, recall, label = 'Train Recall')\n",
    "    plt.plot(epochs_range, val_recall, label = 'Val Recall')\n",
    "    plt.legend()\n",
    "    plt.title('Recall')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(epochs_range, loss, label = 'Train Loss')\n",
    "    plt.plot(epochs_range, val_loss, label = 'Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8t5nzKPxglnl",
    "outputId": "021f7ed1-f039-401d-ac7c-93710b989e4e"
   },
   "outputs": [],
   "source": [
    "train_loss, train_acc, train_prec, train_recall = model.evaluate(train_ds)\n",
    "test_loss, test_acc, test_prec, test_recall     = model.evaluate(test_ds)\n",
    "\n",
    "y_pred_probs = model.predict(test_ds)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis = 0)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"\\nTrain Accuracy: {train_acc:.4f}, Precision: {train_prec:.4f}, Recall: {train_recall:.4f}\")\n",
    "print(f\"Test  Accuracy: {test_acc:.4f}, Precision: {test_prec:.4f}, Recall: {test_recall:.4f}, F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Matrix - Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsxogJl1bsWb",
    "outputId": "1678f458-5e1e-4808-aeaa-47533c4035f5"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names = class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "3WOhV9k4bsS7",
    "outputId": "650efc3b-b978-46ca-e064-6b56f2f153d4"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_true, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(fpr, tpr, label = f\"AUC = {roc_auc:.4f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mj59837wbsPW"
   },
   "source": [
    "* **High AUC Score (0.9862):** The ROC curve shows excellent discrimination between classes, indicating that the model is highly effective at distinguishing real vs fake inputs.\n",
    "\n",
    "* **Strong Test Performance:** The test accuracy is 96.12%, with precision of 97.04%, recall of 88.94%, and F1-score of 92.82%, confirming the model’s robustness and balanced generalization on unseen data.\n",
    "\n",
    "* **Efficient Use of Epochs:** Only 10 epochs were used for training due to time and compute constraints, even when using a GPU. Despite the limited training duration, the model achieved high accuracy and strong generalization. \n",
    "                \n",
    "                Effective transfer learning from ImageNet-pretrained ResNet50.\n",
    "                Squeeze-and-Excitation (SE) blocks helped quickly boost feature focus.\n",
    "\n",
    "\n",
    "\n",
    "* **Confusion Matrix Insights:** \n",
    "            \n",
    "            FAKE samples: 9729 correctly classified, 271 false positives\n",
    "            REAL samples: 8894 correctly classified, 1106 false negatives\n",
    "\n",
    "            This indicates the model is slightly more conservative in detecting real instances.\n",
    "\n",
    "* **Train vs Test Consistency:** With train accuracy at 98.97% and test accuracy at 96.12%, there’s minimal overfitting, showing that fine-tuning with the SE-ResNet model generalizes well.\n",
    "\n",
    "* **Balanced Class Performance:** Both classes (FAKE and REAL) show high precision and recall, with macro and weighted averages of 0.93, indicating balanced and reliable classification.\n",
    "\n",
    "\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "The ResNet50-SE model achieves excellent performance on binary classification of real vs fake images, with high accuracy and a strong AUC. Minor improvements can be made by addressing the false negatives using techniques like data augmentation or class-balanced loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
